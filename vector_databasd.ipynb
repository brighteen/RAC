{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d0cdf943",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import uuid\n",
    "import sqlite3\n",
    "from typing import List\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "from langchain_google_genai import GoogleGenerativeAIEmbeddings\n",
    "from langchain_chroma import Chroma\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bf211940",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load environment variables\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "26d1963a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_file_registered(file_path, namespace: str) -> bool:\n",
    "\n",
    "    path = os.path.join(file_path, namespace)\n",
    "    return os.path.isdir(path)\n",
    "\n",
    "\n",
    "def register_file(file_path, namespace: str):\n",
    "\n",
    "    Chroma(persist_directory=file_path, collection_name=namespace)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4b75a188",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sanitize_namespace(file_path: str) -> str:\n",
    "    base_name = os.path.splitext(os.path.basename(file_path))[0]\n",
    "    # í—ˆìš© ë¬¸ì ì™¸ë¥¼ '_'ë¡œ ì¹˜í™˜\n",
    "    ascii_namespace = re.sub(r\"[^a-zA-Z0-9._-]\", \"_\", base_name)\n",
    "    # ì‹œì‘/ëì´ ì˜ìˆ«ìê°€ ì•„ë‹ ê²½ìš° 'a'ë¡œ ë³´ì •\n",
    "    if not re.match(r\"^[a-zA-Z0-9]\", ascii_namespace):\n",
    "        ascii_namespace = \"a\" + ascii_namespace\n",
    "    if not re.match(r\".*[a-zA-Z0-9]$\", ascii_namespace):\n",
    "        ascii_namespace = ascii_namespace + \"a\"\n",
    "    return ascii_namespace, base_name\n",
    "\n",
    "def load_pdf_chunks(file_path: str) -> List:\n",
    "    loader = PyPDFLoader(file_path)\n",
    "    docs = loader.load()\n",
    "    splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=100)\n",
    "    chunks = splitter.split_documents(docs)\n",
    "    return chunks\n",
    "\n",
    "def embed_and_upsert(database_path: str, chunks: List, namespace: str):\n",
    "    # ì„ë² ë”© ëª¨ë¸ ì´ˆê¸°í™”\n",
    "    embeddings = GoogleGenerativeAIEmbeddings(model=\"models/embedding-001\")\n",
    "\n",
    "    # Chroma ì¸ìŠ¤í„´ìŠ¤ ìƒì„±\n",
    "    chroma = Chroma(\n",
    "        persist_directory=database_path,\n",
    "        collection_name=namespace,\n",
    "        embedding_function=embeddings\n",
    "    )\n",
    "\n",
    "    # ë¬¸ì„œ ì¶”ê°€ (ë‚´ë¶€ì—ì„œ í…ìŠ¤íŠ¸, ë©”íƒ€ë°ì´í„° ë° ë²¡í„° ìë™ ì²˜ë¦¬)\n",
    "    print(f\"ğŸ“¤ Adding {len(chunks)} documents to Chroma collection '{namespace}'...\")\n",
    "    chroma.add_documents(chunks)\n",
    "\n",
    "    # Chroma DBì— ì €ì¥\n",
    "    print(f\"âœ… Upsert complete! namespace = '{namespace}'\")\n",
    "\n",
    "def main(file_path: str, database_path: str):\n",
    "    if not os.path.exists(file_path):\n",
    "        print(f\"âŒ File does not exist: {file_path}\")\n",
    "        return\n",
    "\n",
    "    # ë„¤ì„ìŠ¤í˜ì´ìŠ¤ë¥¼ íŒŒì¼ëª… ê¸°ë°˜ ìë™ ìƒì„±\n",
    "    namespace, basename = sanitize_namespace(file_path)\n",
    "\n",
    "    if is_file_registered(file_path=database_path, namespace=namespace):\n",
    "        print(f\"â„¹ï¸ Collection already exists: {basename} (namespace: {namespace})\")\n",
    "        return\n",
    "\n",
    "    print(f\"ğŸ“„ Loading pdf: {file_path}\")\n",
    "    chunks = load_pdf_chunks(file_path)\n",
    "    print(f\"ğŸ”— Number of chunks: {len(chunks)}\")\n",
    "\n",
    "    if not chunks:\n",
    "        print(\"âŒ No chunk is extracted from pdf.\")\n",
    "        return\n",
    "\n",
    "    embed_and_upsert(database_path, chunks, namespace)\n",
    "\n",
    "    # Register namespace (collection)\n",
    "    register_file(file_path=database_path, namespace=namespace)\n",
    "    print(f\"âœ… Registered collection: {basename} in Chroma.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "21ba4d36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“„ Loading pdf: data/2025í•™ë…„ë„ ì „ì£¼ëŒ€í•™êµ ì •ì‹œ ëª¨ì§‘ìš”ê°•.pdf\n",
      "ğŸ”— Number of chunks: 236\n",
      "ğŸ“¤ Adding 236 documents to Chroma collection '2025_________________a'...\n",
      "âœ… Upsert complete! namespace = '2025_________________a'\n",
      "âœ… Registered collection: 2025í•™ë…„ë„ ì „ì£¼ëŒ€í•™êµ ì •ì‹œ ëª¨ì§‘ìš”ê°• in Chroma.\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    file_path = \"data/2025í•™ë…„ë„ ì „ì£¼ëŒ€í•™êµ ì •ì‹œ ëª¨ì§‘ìš”ê°•.pdf\"\n",
    "    database_path = 'database'\n",
    "    main(file_path=file_path, database_path=database_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15f28375",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
