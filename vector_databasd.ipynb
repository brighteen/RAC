{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d0cdf943",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import uuid\n",
    "import sqlite3\n",
    "from typing import List\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "from langchain_google_genai import GoogleGenerativeAIEmbeddings\n",
    "from langchain_chroma import Chroma\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bf211940",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load environment variables\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "26d1963a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def is_file_registered(file_path, namespace: str) -> bool:\n",
    "#     \"\"\"\n",
    "#     ì£¼ì–´ì§„ ë„¤ì„ìŠ¤í˜ì´ìŠ¤ì˜ ì»¬ë ‰ì…˜ì´ ë²¡í„° ë°ì´í„°ë² ì´ìŠ¤ì— ì´ë¯¸ ë“±ë¡ë˜ì–´ ìˆëŠ”ì§€ í™•ì¸í•©ë‹ˆë‹¤.\n",
    "    \n",
    "#     Args:\n",
    "#         file_path (str): ë²¡í„° ë°ì´í„°ë² ì´ìŠ¤ ë””ë ‰í† ë¦¬ ê²½ë¡œ\n",
    "#         namespace (str): í™•ì¸í•  ì»¬ë ‰ì…˜ì˜ ë„¤ì„ìŠ¤í˜ì´ìŠ¤\n",
    "        \n",
    "#     Returns:\n",
    "#         bool: í•´ë‹¹ ë„¤ì„ìŠ¤í˜ì´ìŠ¤ê°€ ì´ë¯¸ ë“±ë¡ë˜ì–´ ìˆìœ¼ë©´ True, ì•„ë‹ˆë©´ False\n",
    "#     \"\"\"\n",
    "#     path = os.path.join(file_path, namespace)\n",
    "#     return os.path.isdir(path)\n",
    "\n",
    "def is_file_registered(file_path, namespace: str) -> bool:\n",
    "    \"\"\"\n",
    "    ì£¼ì–´ì§„ ë„¤ì„ìŠ¤í˜ì´ìŠ¤ì˜ ì»¬ë ‰ì…˜ì´ ë²¡í„° ë°ì´í„°ë² ì´ìŠ¤ì— ì´ë¯¸ ë“±ë¡ë˜ì–´ ìˆëŠ”ì§€ í™•ì¸í•©ë‹ˆë‹¤.\n",
    "    \n",
    "    Args:\n",
    "        file_path (str): ë²¡í„° ë°ì´í„°ë² ì´ìŠ¤ ë””ë ‰í† ë¦¬ ê²½ë¡œ\n",
    "        namespace (str): í™•ì¸í•  ì»¬ë ‰ì…˜ì˜ ë„¤ì„ìŠ¤í˜ì´ìŠ¤\n",
    "        \n",
    "    Returns:\n",
    "        bool: í•´ë‹¹ ë„¤ì„ìŠ¤í˜ì´ìŠ¤ê°€ ì´ë¯¸ ë“±ë¡ë˜ì–´ ìˆìœ¼ë©´ True, ì•„ë‹ˆë©´ False\n",
    "    \"\"\"\n",
    "    sqlite_path = os.path.join(file_path, \"chroma.sqlite3\")\n",
    "    if not os.path.exists(sqlite_path):\n",
    "        return False\n",
    "    \n",
    "    try:\n",
    "        # SQLite ë°ì´í„°ë² ì´ìŠ¤ì— ì—°ê²°\n",
    "        conn = sqlite3.connect(sqlite_path)\n",
    "        cursor = conn.cursor()\n",
    "        \n",
    "        # collections í…Œì´ë¸”ì—ì„œ í•´ë‹¹ ë„¤ì„ìŠ¤í˜ì´ìŠ¤ ê²€ìƒ‰\n",
    "        cursor.execute(\"SELECT COUNT(*) FROM collections WHERE name = ?\", (namespace,))\n",
    "        count = cursor.fetchone()[0]\n",
    "        \n",
    "        conn.close()\n",
    "        return count > 0\n",
    "    except sqlite3.Error:\n",
    "        # SQLite ì˜¤ë¥˜ ë°œìƒ ì‹œ ê¸°ì¡´ ë°©ì‹ìœ¼ë¡œ í´ë°±\n",
    "        path = os.path.join(file_path, namespace)\n",
    "        return os.path.isdir(path)\n",
    "    \n",
    "\n",
    "def register_file(file_path, namespace: str):\n",
    "    \"\"\"\n",
    "    ìƒˆë¡œìš´ ì»¬ë ‰ì…˜ì„ ë²¡í„° ë°ì´í„°ë² ì´ìŠ¤ì— ë“±ë¡í•©ë‹ˆë‹¤.\n",
    "    ì´ í•¨ìˆ˜ëŠ” ì£¼ì–´ì§„ ë„¤ì„ìŠ¤í˜ì´ìŠ¤ë¡œ Chroma ì¸ìŠ¤í„´ìŠ¤ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.\n",
    "    \n",
    "    Args:\n",
    "        file_path (str): ë²¡í„° ë°ì´í„°ë² ì´ìŠ¤ ë””ë ‰í† ë¦¬ ê²½ë¡œ\n",
    "        namespace (str): ë“±ë¡í•  ì»¬ë ‰ì…˜ì˜ ë„¤ì„ìŠ¤í˜ì´ìŠ¤\n",
    "    \"\"\"\n",
    "    Chroma(persist_directory=file_path, collection_name=namespace)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4b75a188",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sanitize_namespace(file_path: str) -> str:\n",
    "    \"\"\"\n",
    "    íŒŒì¼ ê²½ë¡œì—ì„œ Chroma DB ì»¬ë ‰ì…˜ ë„¤ì„ìŠ¤í˜ì´ìŠ¤ë¡œ ì‚¬ìš©í•  ìˆ˜ ìˆëŠ” ìœ íš¨í•œ ë¬¸ìì—´ì„ ìƒì„±í•©ë‹ˆë‹¤.\n",
    "    \n",
    "    Args:\n",
    "        file_path (str): ì›ë³¸ íŒŒì¼ ê²½ë¡œ\n",
    "        \n",
    "    Returns:\n",
    "        tuple: (ì •ì œëœ ë„¤ì„ìŠ¤í˜ì´ìŠ¤, ì›ë³¸ íŒŒì¼ëª…)\n",
    "            - ì •ì œëœ ë„¤ì„ìŠ¤í˜ì´ìŠ¤ëŠ” ì˜ìˆ«ì, ì , ë°‘ì¤„, í•˜ì´í”ˆë§Œ í¬í•¨í•©ë‹ˆë‹¤.\n",
    "            - ì‹œì‘ê³¼ ëì€ ë°˜ë“œì‹œ ì˜ìˆ«ìì—¬ì•¼ í•©ë‹ˆë‹¤.\n",
    "    \"\"\"\n",
    "    base_name = os.path.splitext(os.path.basename(file_path))[0]\n",
    "    # í—ˆìš© ë¬¸ì ì™¸ë¥¼ '_'ë¡œ ì¹˜í™˜\n",
    "    ascii_namespace = re.sub(r\"[^a-zA-Z0-9._-]\", \"_\", base_name)\n",
    "    # ì‹œì‘/ëì´ ì˜ìˆ«ìê°€ ì•„ë‹ ê²½ìš° 'a'ë¡œ ë³´ì •\n",
    "    if not re.match(r\"^[a-zA-Z0-9]\", ascii_namespace):\n",
    "        ascii_namespace = \"a\" + ascii_namespace\n",
    "    if not re.match(r\".*[a-zA-Z0-9]$\", ascii_namespace):\n",
    "        ascii_namespace = ascii_namespace + \"a\"\n",
    "    return ascii_namespace, base_name\n",
    "\n",
    "def load_pdf_chunks(file_path: str) -> List:\n",
    "    \"\"\"\n",
    "    PDF íŒŒì¼ì„ ë¡œë“œí•˜ê³  ì‘ì€ í…ìŠ¤íŠ¸ ì²­í¬ë¡œ ë¶„í• í•©ë‹ˆë‹¤.\n",
    "    \n",
    "    Args:\n",
    "        file_path (str): PDF íŒŒì¼ ê²½ë¡œ\n",
    "        \n",
    "    Returns:\n",
    "        List: Document ê°ì²´ì˜ ë¦¬ìŠ¤íŠ¸. ê° DocumentëŠ” í…ìŠ¤íŠ¸ ì²­í¬ì™€ ë©”íƒ€ë°ì´í„°ë¥¼ í¬í•¨í•©ë‹ˆë‹¤.\n",
    "    \"\"\"\n",
    "    loader = PyPDFLoader(file_path)\n",
    "    docs = loader.load()\n",
    "    splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=100)\n",
    "    chunks = splitter.split_documents(docs)\n",
    "    return chunks\n",
    "\n",
    "def embed_and_upsert(database_path: str, chunks: List, namespace: str):\n",
    "    \"\"\"\n",
    "    í…ìŠ¤íŠ¸ ì²­í¬ë¥¼ ì„ë² ë”©í•˜ê³  Chroma ë²¡í„° ë°ì´í„°ë² ì´ìŠ¤ì— ì—…ì„œíŠ¸í•©ë‹ˆë‹¤.\n",
    "    \n",
    "    Args:\n",
    "        database_path (str): ë²¡í„° ë°ì´í„°ë² ì´ìŠ¤ ì €ì¥ ê²½ë¡œ\n",
    "        chunks (List): ì„ë² ë”©í•  Document ê°ì²´ì˜ ë¦¬ìŠ¤íŠ¸\n",
    "        namespace (str): ì €ì¥í•  Chroma ì»¬ë ‰ì…˜ ë„¤ì„ìŠ¤í˜ì´ìŠ¤\n",
    "    \"\"\"\n",
    "    # ì„ë² ë”© ëª¨ë¸ ì´ˆê¸°í™”\n",
    "    embeddings = GoogleGenerativeAIEmbeddings(model=\"models/embedding-001\")\n",
    "\n",
    "    # Chroma ì¸ìŠ¤í„´ìŠ¤ ìƒì„±\n",
    "    chroma = Chroma(\n",
    "        persist_directory=database_path,\n",
    "        collection_name=namespace,\n",
    "        embedding_function=embeddings\n",
    "    )\n",
    "\n",
    "    # ë¬¸ì„œ ì¶”ê°€ (ë‚´ë¶€ì—ì„œ í…ìŠ¤íŠ¸, ë©”íƒ€ë°ì´í„° ë° ë²¡í„° ìë™ ì²˜ë¦¬)\n",
    "    print(f\"ğŸ“¤ Adding {len(chunks)} documents to Chroma collection '{namespace}'...\")\n",
    "    chroma.add_documents(chunks)\n",
    "\n",
    "    # Chroma DBì— ì €ì¥\n",
    "    print(f\"âœ… Upsert complete! namespace = '{namespace}'\")\n",
    "\n",
    "def main(file_path: str, database_path: str):\n",
    "    \"\"\"\n",
    "    PDF íŒŒì¼ì„ ì²˜ë¦¬í•˜ì—¬ ë²¡í„° ë°ì´í„°ë² ì´ìŠ¤ì— ì €ì¥í•˜ëŠ” ì „ì²´ í”„ë¡œì„¸ìŠ¤ë¥¼ ê´€ë¦¬í•©ë‹ˆë‹¤.\n",
    "    \n",
    "    Args:\n",
    "        file_path (str): ì²˜ë¦¬í•  PDF íŒŒì¼ ê²½ë¡œ\n",
    "        database_path (str): ë²¡í„° ë°ì´í„°ë² ì´ìŠ¤ ì €ì¥ ê²½ë¡œ\n",
    "    \"\"\"\n",
    "    if not os.path.exists(file_path):\n",
    "        print(f\"âŒ File does not exist: {file_path}\")\n",
    "        return\n",
    "\n",
    "    # ë„¤ì„ìŠ¤í˜ì´ìŠ¤ë¥¼ íŒŒì¼ëª… ê¸°ë°˜ ìë™ ìƒì„±\n",
    "    namespace, basename = sanitize_namespace(file_path)\n",
    "\n",
    "    if is_file_registered(file_path=database_path, namespace=namespace):\n",
    "        print(f\"â„¹ï¸ Collection already exists: {basename} (namespace: {namespace})\")\n",
    "        return\n",
    "\n",
    "    print(f\"ğŸ“„ Loading pdf: {file_path}\")\n",
    "    chunks = load_pdf_chunks(file_path)\n",
    "    print(f\"ğŸ”— Number of chunks: {len(chunks)}\")\n",
    "\n",
    "    if not chunks:\n",
    "        print(\"âŒ No chunk is extracted from pdf.\")\n",
    "        return\n",
    "\n",
    "    embed_and_upsert(database_path, chunks, namespace)\n",
    "\n",
    "    # Register namespace (collection)\n",
    "    register_file(file_path=database_path, namespace=namespace)\n",
    "    print(f\"âœ… Registered collection: {basename} in Chroma.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "21ba4d36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "â„¹ï¸ Collection already exists: 2024-1í•™ê¸°_ì¼ë°˜ëŒ€í•™ì› (namespace: 2024-1________a)\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    # file_path = \"data/2025í•™ë…„ë„ ì „ì£¼ëŒ€í•™êµ ì •ì‹œ ëª¨ì§‘ìš”ê°•.pdf\"\n",
    "    file_path = \"data/2024-1í•™ê¸°_ì¼ë°˜ëŒ€í•™ì›.pdf\"\n",
    "    \n",
    "    database_path = 'database'\n",
    "    main(file_path=file_path, database_path=database_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4298551",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5596ad3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "15f28375",
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_similar_documents(query: str, database_path: str, namespace: str, top_k: int = 3):\n",
    "    \"\"\"\n",
    "    ì‚¬ìš©ì ì§ˆì˜ì™€ ì˜ë¯¸ì ìœ¼ë¡œ ìœ ì‚¬í•œ ë¬¸ì„œë¥¼ ë²¡í„° ë°ì´í„°ë² ì´ìŠ¤ì—ì„œ ê²€ìƒ‰í•©ë‹ˆë‹¤.\n",
    "    \n",
    "    Args:\n",
    "        query (str): ì‚¬ìš©ì ì§ˆì˜\n",
    "        database_path (str): ë²¡í„° ë°ì´í„°ë² ì´ìŠ¤ ê²½ë¡œ\n",
    "        namespace (str): ê²€ìƒ‰í•  ì»¬ë ‰ì…˜ ë„¤ì„ìŠ¤í˜ì´ìŠ¤\n",
    "        top_k (int, optional): ë°˜í™˜í•  ìµœëŒ€ ë¬¸ì„œ ìˆ˜. ê¸°ë³¸ê°’ì€ 3ì…ë‹ˆë‹¤.\n",
    "        \n",
    "    Returns:\n",
    "        List: ìœ ì‚¬í•œ ë¬¸ì„œ ëª©ë¡\n",
    "    \"\"\"\n",
    "    # ì„ë² ë”© ëª¨ë¸ ì´ˆê¸°í™”\n",
    "    embeddings = GoogleGenerativeAIEmbeddings(model=\"models/embedding-001\")\n",
    "    \n",
    "    # Chroma ì¸ìŠ¤í„´ìŠ¤ ìƒì„±\n",
    "    chroma = Chroma(\n",
    "        persist_directory=database_path,\n",
    "        collection_name=namespace,\n",
    "        embedding_function=embeddings\n",
    "    )\n",
    "    \n",
    "    # ìœ ì‚¬ ë¬¸ì„œ ê²€ìƒ‰\n",
    "    results = chroma.similarity_search(query, k=top_k)\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "81811771",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from langchain.schema.document import Document\n",
    "\n",
    "def search_with_sklearn_similarity(query: str, database_path: str, namespace: str, top_k: int = 3):\n",
    "    \"\"\"\n",
    "    ì‚¬ìš©ì ì§ˆì˜ì™€ ì˜ë¯¸ì ìœ¼ë¡œ ìœ ì‚¬í•œ ë¬¸ì„œë¥¼ ê²€ìƒ‰í•˜ê³  scikit-learnì„ ì‚¬ìš©í•˜ì—¬ ì½”ì‚¬ì¸ ìœ ì‚¬ë„ ì ìˆ˜ë¥¼ ê³„ì‚°í•©ë‹ˆë‹¤.\n",
    "    \n",
    "    Args:\n",
    "        query (str): ì‚¬ìš©ì ì§ˆì˜\n",
    "        database_path (str): ë²¡í„° ë°ì´í„°ë² ì´ìŠ¤ ê²½ë¡œ\n",
    "        namespace (str): ê²€ìƒ‰í•  ì»¬ë ‰ì…˜ ë„¤ì„ìŠ¤í˜ì´ìŠ¤\n",
    "        top_k (int, optional): ë°˜í™˜í•  ìµœëŒ€ ë¬¸ì„œ ìˆ˜. ê¸°ë³¸ê°’ì€ 3ì…ë‹ˆë‹¤.\n",
    "        \n",
    "    Returns:\n",
    "        List[Tuple]: (ë¬¸ì„œ, ìœ ì‚¬ë„ ì ìˆ˜) ìŒì˜ ë¦¬ìŠ¤íŠ¸. ìœ ì‚¬ë„ ì ìˆ˜ ë‚´ë¦¼ì°¨ìˆœìœ¼ë¡œ ì •ë ¬ë©ë‹ˆë‹¤.\n",
    "    \"\"\"\n",
    "    # ì„ë² ë”© ëª¨ë¸ ì´ˆê¸°í™”\n",
    "    embeddings = GoogleGenerativeAIEmbeddings(model=\"models/embedding-001\")\n",
    "    \n",
    "    # Chroma ì¸ìŠ¤í„´ìŠ¤ ìƒì„±\n",
    "    chroma = Chroma(\n",
    "        persist_directory=database_path,\n",
    "        collection_name=namespace,\n",
    "        embedding_function=embeddings\n",
    "    )\n",
    "    \n",
    "    # ì „ì²´ ë¬¸ì„œ ê°€ì ¸ì˜¤ê¸°\n",
    "    collection_data = chroma.get()\n",
    "    \n",
    "    if not collection_data['ids']:\n",
    "        return []\n",
    "    \n",
    "    # ì§ˆì˜ ì„ë² ë”© ìƒì„±\n",
    "    query_embedding = embeddings.embed_query(query)\n",
    "    \n",
    "    # ë¬¸ì„œ ì„ë² ë”©ê³¼ ì§ˆì˜ ì„ë² ë”© ê°„ì˜ ì½”ì‚¬ì¸ ìœ ì‚¬ë„ ê³„ì‚°\n",
    "    doc_embeddings = np.array(collection_data['embeddings'])\n",
    "    query_embedding_array = np.array(query_embedding).reshape(1, -1)\n",
    "    \n",
    "    similarities = cosine_similarity(query_embedding_array, doc_embeddings)[0]\n",
    "    \n",
    "    # ë¬¸ì„œ, ë©”íƒ€ë°ì´í„°, ìœ ì‚¬ë„ ì ìˆ˜ë¥¼ í•¨ê»˜ ì €ì¥\n",
    "    results = []\n",
    "    for i, (doc_id, doc_text, metadata, similarity) in enumerate(zip(\n",
    "            collection_data['ids'],\n",
    "            collection_data['documents'],\n",
    "            collection_data['metadatas'],\n",
    "            similarities\n",
    "        )):\n",
    "        doc = Document(page_content=doc_text, metadata=metadata)\n",
    "        results.append((doc, similarity))\n",
    "    \n",
    "    # ìœ ì‚¬ë„ ì ìˆ˜ë¡œ ë‚´ë¦¼ì°¨ìˆœ ì •ë ¬\n",
    "    results.sort(key=lambda x: x[1], reverse=True)\n",
    "    \n",
    "    # top-k ê²°ê³¼ ë°˜í™˜\n",
    "    return results[:top_k]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b50423f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== scikit-learnì„ ì‚¬ìš©í•œ ì½”ì‚¬ì¸ ìœ ì‚¬ë„ ê²€ìƒ‰ =====\n",
      "\n",
      "\n",
      "===== ì¿¼ë¦¬: ëŒ€í•™ì› ìˆ˜ì—…ë£Œì— ëŒ€í•´ ì•Œë ¤ì¤˜ =====\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'namespace' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[9]\u001b[39m\u001b[32m, line 16\u001b[39m\n\u001b[32m     11\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m query \u001b[38;5;129;01min\u001b[39;00m queries:\n\u001b[32m     12\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m===== ì¿¼ë¦¬: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mquery\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m =====\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     13\u001b[39m     results = search_with_sklearn_similarity(\n\u001b[32m     14\u001b[39m         query=query, \n\u001b[32m     15\u001b[39m         database_path=database_path, \n\u001b[32m---> \u001b[39m\u001b[32m16\u001b[39m         namespace=\u001b[43mnamespace\u001b[49m, \n\u001b[32m     17\u001b[39m         top_k=\u001b[32m3\u001b[39m\n\u001b[32m     18\u001b[39m     )\n\u001b[32m     20\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m i, (doc, score) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(results):\n\u001b[32m     21\u001b[39m         \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mê²°ê³¼ \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi+\u001b[32m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m:\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mNameError\u001b[39m: name 'namespace' is not defined"
     ]
    }
   ],
   "source": [
    "# scikit-learnì„ ì‚¬ìš©í•œ ì½”ì‚¬ì¸ ìœ ì‚¬ë„ ê²€ìƒ‰ í…ŒìŠ¤íŠ¸\n",
    "print(\"\\n===== scikit-learnì„ ì‚¬ìš©í•œ ì½”ì‚¬ì¸ ìœ ì‚¬ë„ ê²€ìƒ‰ =====\\n\")\n",
    "\n",
    "queries = [\n",
    "    \"ëŒ€í•™ì› ìˆ˜ì—…ë£Œì— ëŒ€í•´ ì•Œë ¤ì¤˜\",\n",
    "    \"ë“±ë¡ê¸ˆ ë‚©ë¶€ ë°©ë²•ì€?\",\n",
    "    \"í•™ì‚¬ì¼ì •ì— ëŒ€í•´ ì•Œë ¤ì¤˜\",\n",
    "    \"ì¡¸ì—… ìš”ê±´ì€ ë¬´ì—‡ì¸ê°€ìš”?\"\n",
    "]\n",
    "\n",
    "for query in queries:\n",
    "    print(f\"\\n===== ì¿¼ë¦¬: {query} =====\")\n",
    "    results = search_with_sklearn_similarity(\n",
    "        query=query, \n",
    "        database_path=database_path, \n",
    "        namespace=namespace, \n",
    "        top_k=3\n",
    "    )\n",
    "    \n",
    "    for i, (doc, score) in enumerate(results):\n",
    "        print(f\"ê²°ê³¼ {i+1}:\")\n",
    "        print(f\"ìœ ì‚¬ë„ ì ìˆ˜: {score:.4f}\")  # ì†Œìˆ˜ì  4ìë¦¬ê¹Œì§€ í‘œì‹œ\n",
    "        print(f\"ë‚´ìš©: {doc.page_content[:100]}...\")  # ë‚´ìš© ì¼ë¶€ë§Œ ì¶œë ¥\n",
    "        print(f\"ë©”íƒ€ë°ì´í„°: {doc.metadata}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e299df3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
